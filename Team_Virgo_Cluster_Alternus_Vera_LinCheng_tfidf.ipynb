{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Team_Virgo_Cluster_Alternus_Vera_LinCheng_tfidf.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "myrJOvEVIhue"
      },
      "cell_type": "markdown",
      "source": [
        "## Team Virgo Cluster - Lin Cheng\n",
        "### Team document link:\n",
        "https://colab.research.google.com/drive/1573CEdUu47ptIx9mxFUGxPBTE7mamCrS\n",
        "\n",
        "### My progress:\n",
        "- Starting from last week's work in which we got accuracy 0.9 on the LiarLiar dataset, this week I leverage Hyunwook and Yu's data enrichment source, and tried more approaches to enhance the performance.  \n",
        "- With the additional 50K non-fake news samples, I can now make all the LiarLiar data \"bs\" as some types are very few and have close meaning to bs:\n",
        "\"bias            443\n",
        "bs            11492\n",
        "conspiracy      430\n",
        "fake             19\n",
        "hate            246\n",
        "junksci         102\n",
        "satire          146\n",
        "state           121\".  \n",
        "- Calculate TF-IDF scores and get the vectorised doc-word metrix for further modeling.  \n",
        "- Add compound feature sentiment.  \n",
        "- Apply differnt ALGs and turn the models, found the best accuracy 97% with LogisticRegression(class_weight={\"bs\":5,\"non-bs\":3}, {'C': 1, 'penalty': 'l1'}), which is a notable improvement. \n",
        "- Also played with LDA to see how it works for topic modeling.  \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ebnN4ikZzQtu"
      },
      "cell_type": "markdown",
      "source": [
        "## Datasets\n",
        "Original Kaggle fake news dataset: \n",
        "https://github.com/synle/machine-learning-sample-dataset/raw/master/liar_dataset/kaggle/kaggle-fake.csv\n",
        "\n",
        "Enriched Kaggle news dataset (50,000 verified non-fake news):\n",
        "https://github.com/h7shin/all_news_dataset_kaggle/raw/master/articles1.csv"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "vymCp8X8IHEk",
        "outputId": "7b3c5c4c-c74d-46ba-ed06-fb8635e1561b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "cell_type": "code",
      "source": [
        "# dependencies\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "# download nltk stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zmVds2371DXz",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import requests\n",
        "\n",
        "def get_parsed_data2(url):\n",
        "    return pd.read_csv(io.StringIO(requests.get(url).content.decode('utf-8')), sep=',', header='infer')\n",
        "\n",
        "# download and parse the dataset...\n",
        "data_kg_fake_news = get_parsed_data2('https://github.com/synle/machine-learning-sample-dataset/raw/master/liar_dataset/kaggle/kaggle-fake.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3nNG0s4O2bGa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_kg_nonfake_news = get_parsed_data2('https://github.com/h7shin/all_news_dataset_kaggle/raw/master/articles1.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tD-Osnm12bGc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_kg_nonfake_news.rename(columns={\"content\": \"text\"}, inplace=True)\n",
        "data_kg_nonfake_news['type'] = 'non-bs'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-lsJp6YS2bGf",
        "colab_type": "code",
        "outputId": "f8d7222d-589c-41d2-bebd-20ffb07554de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "cell_type": "code",
      "source": [
        "print(data_kg_nonfake_news.shape)\n",
        "data_kg_nonfake_news.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 11)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>publication</th>\n",
              "      <th>author</th>\n",
              "      <th>date</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>url</th>\n",
              "      <th>text</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>17283</td>\n",
              "      <td>House Republicans Fret About Winning Their Hea...</td>\n",
              "      <td>New York Times</td>\n",
              "      <td>Carl Hulse</td>\n",
              "      <td>2016-12-31</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>WASHINGTON  —   Congressional Republicans have...</td>\n",
              "      <td>non-bs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>17284</td>\n",
              "      <td>Rift Between Officers and Residents as Killing...</td>\n",
              "      <td>New York Times</td>\n",
              "      <td>Benjamin Mueller and Al Baker</td>\n",
              "      <td>2017-06-19</td>\n",
              "      <td>2017.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>After the bullet shells get counted, the blood...</td>\n",
              "      <td>non-bs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>17285</td>\n",
              "      <td>Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...</td>\n",
              "      <td>New York Times</td>\n",
              "      <td>Margalit Fox</td>\n",
              "      <td>2017-01-06</td>\n",
              "      <td>2017.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>When Walt Disney’s “Bambi” opened in 1942, cri...</td>\n",
              "      <td>non-bs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>17286</td>\n",
              "      <td>Among Deaths in 2016, a Heavy Toll in Pop Musi...</td>\n",
              "      <td>New York Times</td>\n",
              "      <td>William McDonald</td>\n",
              "      <td>2017-04-10</td>\n",
              "      <td>2017.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Death may be the great equalizer, but it isn’t...</td>\n",
              "      <td>non-bs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>17287</td>\n",
              "      <td>Kim Jong-un Says North Korea Is Preparing to T...</td>\n",
              "      <td>New York Times</td>\n",
              "      <td>Choe Sang-Hun</td>\n",
              "      <td>2017-01-02</td>\n",
              "      <td>2017.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SEOUL, South Korea  —   North Korea’s leader, ...</td>\n",
              "      <td>non-bs</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0     id                                              title  \\\n",
              "0           0  17283  House Republicans Fret About Winning Their Hea...   \n",
              "1           1  17284  Rift Between Officers and Residents as Killing...   \n",
              "2           2  17285  Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...   \n",
              "3           3  17286  Among Deaths in 2016, a Heavy Toll in Pop Musi...   \n",
              "4           4  17287  Kim Jong-un Says North Korea Is Preparing to T...   \n",
              "\n",
              "      publication                         author        date    year  month  \\\n",
              "0  New York Times                     Carl Hulse  2016-12-31  2016.0   12.0   \n",
              "1  New York Times  Benjamin Mueller and Al Baker  2017-06-19  2017.0    6.0   \n",
              "2  New York Times                   Margalit Fox  2017-01-06  2017.0    1.0   \n",
              "3  New York Times               William McDonald  2017-04-10  2017.0    4.0   \n",
              "4  New York Times                  Choe Sang-Hun  2017-01-02  2017.0    1.0   \n",
              "\n",
              "   url                                               text    type  \n",
              "0  NaN  WASHINGTON  —   Congressional Republicans have...  non-bs  \n",
              "1  NaN  After the bullet shells get counted, the blood...  non-bs  \n",
              "2  NaN  When Walt Disney’s “Bambi” opened in 1942, cri...  non-bs  \n",
              "3  NaN  Death may be the great equalizer, but it isn’t...  non-bs  \n",
              "4  NaN  SEOUL, South Korea  —   North Korea’s leader, ...  non-bs  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wflDgVH289N1",
        "outputId": "a29b88be-938a-430b-c312-95f543950635",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "cell_type": "code",
      "source": [
        "data_kg_fake_news.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uuid</th>\n",
              "      <th>ord_in_thread</th>\n",
              "      <th>author</th>\n",
              "      <th>published</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>language</th>\n",
              "      <th>crawled</th>\n",
              "      <th>site_url</th>\n",
              "      <th>country</th>\n",
              "      <th>domain_rank</th>\n",
              "      <th>thread_title</th>\n",
              "      <th>spam_score</th>\n",
              "      <th>main_img_url</th>\n",
              "      <th>replies_count</th>\n",
              "      <th>participants_count</th>\n",
              "      <th>likes</th>\n",
              "      <th>comments</th>\n",
              "      <th>shares</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6a175f46bcd24d39b3e962ad0f29936721db70db</td>\n",
              "      <td>0</td>\n",
              "      <td>Barracuda Brigade</td>\n",
              "      <td>2016-10-26T21:41:00.000+03:00</td>\n",
              "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
              "      <td>Print They should pay all the back all the mon...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-10-27T01:49:27.168+03:00</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>US</td>\n",
              "      <td>25689.0</td>\n",
              "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>bias</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2bdc29d12605ef9cf3f09f9875040a7113be5d5b</td>\n",
              "      <td>0</td>\n",
              "      <td>reasoning with facts</td>\n",
              "      <td>2016-10-29T08:47:11.259+03:00</td>\n",
              "      <td>Re: Why Did Attorney General Loretta Lynch Ple...</td>\n",
              "      <td>Why Did Attorney General Loretta Lynch Plead T...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-10-29T08:47:11.259+03:00</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>US</td>\n",
              "      <td>25689.0</td>\n",
              "      <td>Re: Why Did Attorney General Loretta Lynch Ple...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>bias</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c70e149fdd53de5e61c29281100b9de0ed268bc3</td>\n",
              "      <td>0</td>\n",
              "      <td>Barracuda Brigade</td>\n",
              "      <td>2016-10-31T01:41:49.479+02:00</td>\n",
              "      <td>BREAKING: Weiner Cooperating With FBI On Hilla...</td>\n",
              "      <td>Red State : \\nFox News Sunday reported this mo...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-10-31T01:41:49.479+02:00</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>US</td>\n",
              "      <td>25689.0</td>\n",
              "      <td>BREAKING: Weiner Cooperating With FBI On Hilla...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>bias</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7cf7c15731ac2a116dd7f629bd57ea468ed70284</td>\n",
              "      <td>0</td>\n",
              "      <td>Fed Up</td>\n",
              "      <td>2016-11-01T05:22:00.000+02:00</td>\n",
              "      <td>PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...</td>\n",
              "      <td>Email Kayla Mueller was a prisoner and torture...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-11-01T15:46:26.304+02:00</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>US</td>\n",
              "      <td>25689.0</td>\n",
              "      <td>PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...</td>\n",
              "      <td>0.068</td>\n",
              "      <td>http://100percentfedup.com/wp-content/uploads/...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>bias</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0206b54719c7e241ffe0ad4315b808290dbe6c0f</td>\n",
              "      <td>0</td>\n",
              "      <td>Fed Up</td>\n",
              "      <td>2016-11-01T21:56:00.000+02:00</td>\n",
              "      <td>FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...</td>\n",
              "      <td>Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-11-01T23:59:42.266+02:00</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>US</td>\n",
              "      <td>25689.0</td>\n",
              "      <td>FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...</td>\n",
              "      <td>0.865</td>\n",
              "      <td>http://100percentfedup.com/wp-content/uploads/...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>bias</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       uuid  ord_in_thread  \\\n",
              "0  6a175f46bcd24d39b3e962ad0f29936721db70db              0   \n",
              "1  2bdc29d12605ef9cf3f09f9875040a7113be5d5b              0   \n",
              "2  c70e149fdd53de5e61c29281100b9de0ed268bc3              0   \n",
              "3  7cf7c15731ac2a116dd7f629bd57ea468ed70284              0   \n",
              "4  0206b54719c7e241ffe0ad4315b808290dbe6c0f              0   \n",
              "\n",
              "                 author                      published  \\\n",
              "0     Barracuda Brigade  2016-10-26T21:41:00.000+03:00   \n",
              "1  reasoning with facts  2016-10-29T08:47:11.259+03:00   \n",
              "2     Barracuda Brigade  2016-10-31T01:41:49.479+02:00   \n",
              "3                Fed Up  2016-11-01T05:22:00.000+02:00   \n",
              "4                Fed Up  2016-11-01T21:56:00.000+02:00   \n",
              "\n",
              "                                               title  \\\n",
              "0  Muslims BUSTED: They Stole Millions In Gov’t B...   \n",
              "1  Re: Why Did Attorney General Loretta Lynch Ple...   \n",
              "2  BREAKING: Weiner Cooperating With FBI On Hilla...   \n",
              "3  PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...   \n",
              "4  FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...   \n",
              "\n",
              "                                                text language  \\\n",
              "0  Print They should pay all the back all the mon...  english   \n",
              "1  Why Did Attorney General Loretta Lynch Plead T...  english   \n",
              "2  Red State : \\nFox News Sunday reported this mo...  english   \n",
              "3  Email Kayla Mueller was a prisoner and torture...  english   \n",
              "4  Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...  english   \n",
              "\n",
              "                         crawled             site_url country  domain_rank  \\\n",
              "0  2016-10-27T01:49:27.168+03:00  100percentfedup.com      US      25689.0   \n",
              "1  2016-10-29T08:47:11.259+03:00  100percentfedup.com      US      25689.0   \n",
              "2  2016-10-31T01:41:49.479+02:00  100percentfedup.com      US      25689.0   \n",
              "3  2016-11-01T15:46:26.304+02:00  100percentfedup.com      US      25689.0   \n",
              "4  2016-11-01T23:59:42.266+02:00  100percentfedup.com      US      25689.0   \n",
              "\n",
              "                                        thread_title  spam_score  \\\n",
              "0  Muslims BUSTED: They Stole Millions In Gov’t B...       0.000   \n",
              "1  Re: Why Did Attorney General Loretta Lynch Ple...       0.000   \n",
              "2  BREAKING: Weiner Cooperating With FBI On Hilla...       0.000   \n",
              "3  PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...       0.068   \n",
              "4  FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...       0.865   \n",
              "\n",
              "                                        main_img_url  replies_count  \\\n",
              "0  http://bb4sp.com/wp-content/uploads/2016/10/Fu...              0   \n",
              "1  http://bb4sp.com/wp-content/uploads/2016/10/Fu...              0   \n",
              "2  http://bb4sp.com/wp-content/uploads/2016/10/Fu...              0   \n",
              "3  http://100percentfedup.com/wp-content/uploads/...              0   \n",
              "4  http://100percentfedup.com/wp-content/uploads/...              0   \n",
              "\n",
              "   participants_count  likes  comments  shares  type  \n",
              "0                   1      0         0       0  bias  \n",
              "1                   1      0         0       0  bias  \n",
              "2                   1      0         0       0  bias  \n",
              "3                   0      0         0       0  bias  \n",
              "4                   0      0         0       0  bias  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "sScy8EdX2bGp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Transform data\n",
        "\n",
        "Combine those two datasets, mark data \"bias 443 bs 11492 conspiracy 430 fake 19 hate 246 junksci 102 satire 146 state 121\" to \"bs\"."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "G06Hf4XZPWYW",
        "outputId": "304d2d1b-b4ae-482d-a7b5-2676f231df64",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk import word_tokenize\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from string import punctuation\n",
        "from nltk import PorterStemmer\n",
        "import copy \n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "cachedStopWords = set(stopwords.words('english') + list(punctuation) + [''])\n",
        "print(data_kg_fake_news.shape)\n",
        "print(data_kg_fake_news.groupby(['type'])['type'].count())\n",
        "\n",
        "print(data_kg_nonfake_news.shape)\n",
        "print(data_kg_nonfake_news.groupby(['type'])['type'].count())\n",
        "\n",
        "data_kg_fake_news_b=copy.deepcopy(data_kg_fake_news);\n",
        "data_kg_fake_news_b.loc[data_kg_fake_news_b['type']!='non-bs', 'type'] = 'bs'\n",
        "\n",
        "all_data = pd.concat([data_kg_fake_news_b[['text','type']], data_kg_nonfake_news[['text','type']]])\n",
        "\n",
        "print(all_data.groupby(['type'])['type'].count())\n",
        "\n",
        "print(all_data.shape)\n",
        "X=all_data['text'].astype('U')\n",
        "y=all_data['type']"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "(12999, 20)\n",
            "type\n",
            "bias            443\n",
            "bs            11492\n",
            "conspiracy      430\n",
            "fake             19\n",
            "hate            246\n",
            "junksci         102\n",
            "satire          146\n",
            "state           121\n",
            "Name: type, dtype: int64\n",
            "(50000, 11)\n",
            "type\n",
            "non-bs    50000\n",
            "Name: type, dtype: int64\n",
            "type\n",
            "bs        12999\n",
            "non-bs    50000\n",
            "Name: type, dtype: int64\n",
            "(62999, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XQV4Lk1q2bHx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## TF-IDF\n",
        "\n",
        "Now try to use TfidfVectorizer to get a matrix for further classification. Also tried applying SVD for dimension reduction."
      ]
    },
    {
      "metadata": {
        "id": "C-4QbFaK2bH-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.preprocessing import LabelEncoder, Imputer, MaxAbsScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import metrics\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def tokenize2(text):\n",
        "    min_length = 3\n",
        "    words = map(lambda word: word.lower(), word_tokenize(text))\n",
        "    words = [word for word in words if word not in cachedStopWords]\n",
        "    tokens = list(map(lambda token: PorterStemmer().stem(token), words))\n",
        "    p = re.compile('[a-zA-Z]+')\n",
        "    filtered_tokens = list(filter(lambda token: p.match(token) and len(token) >= min_length, tokens))\n",
        "    return filtered_tokens\n",
        "\n",
        "vectorizer = TfidfVectorizer(tokenizer=tokenize2, max_features=2000)\n",
        "svd_model = TruncatedSVD(n_components=200,       \n",
        "                         algorithm='randomized',\n",
        "                         n_iter=10)\n",
        "# svd_transformer = Pipeline([('tfidf', vectorizer), \n",
        "#                             ('svd', svd_model)])\n",
        "svd_transformer=vectorizer\n",
        "    \n",
        "vectorised_documents = svd_transformer.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "al-0MxTN2F17",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Add  Sentiment feature"
      ]
    },
    {
      "metadata": {
        "id": "jDniWG0R2Lof",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "37f2480b-d6b1-4729-9814-12e1bf6d631f"
      },
      "cell_type": "code",
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "def sentiment(x):\n",
        "    score = sid.polarity_scores(x)\n",
        "    return score['compound']\n",
        "    \n",
        "sentiment = all_data['text'].astype('U').apply(lambda x : sentiment(x))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pI9AdDbfDBaR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = pd.concat([sentiment.reset_index(),\n",
        "                        pd.DataFrame(vectorised_documents.toarray(),\n",
        "                        columns=vectorizer.vocabulary_)],axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_U50OMnWIpd1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Modeling and tuning\n",
        "- Random forest  \n",
        "- SVM  \n",
        "- Logistic Regression"
      ]
    },
    {
      "metadata": {
        "id": "TJ-SHmcsKDlL",
        "colab_type": "code",
        "outputId": "ecffd9ff-6919-417f-9f3d-53e995d3db8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "cell_type": "code",
      "source": [
        "clf=RandomForestClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "feature_imp = pd.Series(clf.feature_importances_,index=list(X)).sort_values(ascending=False).nlargest(20)\n",
        "print(feature_imp)\n",
        "\n",
        "y_pred=clf.predict(X_test)\n",
        "print(y_test.value_counts(sort=False))\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(metrics.confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "index       0.191349\n",
            "duti        0.023788\n",
            "tend        0.018595\n",
            "appear      0.016418\n",
            "except      0.013192\n",
            "quickli     0.012568\n",
            "ukrain      0.011429\n",
            "carolina    0.009436\n",
            "panel       0.008980\n",
            "cancer      0.008024\n",
            "scandal     0.007848\n",
            "obtain      0.007031\n",
            "defend      0.006779\n",
            "contact     0.005981\n",
            "key         0.005947\n",
            "ms.         0.005886\n",
            "object      0.005816\n",
            "remark      0.005783\n",
            "soon        0.005269\n",
            "fast        0.004903\n",
            "dtype: float64\n",
            "bs         3844\n",
            "non-bs    15056\n",
            "Name: type, dtype: int64\n",
            "Accuracy: 0.9496825396825397\n",
            "[[ 3153   691]\n",
            " [  260 14796]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HdY5Orq5wJi3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Caution: SLOW\n",
        "# from sklearn.preprocessing import MaxAbsScaler\n",
        "# from sklearn import svm\n",
        "\n",
        "# scaler = MaxAbsScaler()\n",
        "# vectorised_train_documents = scaler.fit_transform(vectorised_train_documents)\n",
        "\n",
        "# svc = svm.SVC()\n",
        "# parameters = {'kernel':('linear','sigmoid')}\n",
        "# lr_gridCV = GridSearchCV(svc, parameters, cv=5, scoring='accuracy')\n",
        "# lr_gridCV = lr_gridCV.fit(vectorised_train_documents, y_train)\n",
        "\n",
        "# print(lr_gridCV.best_score_)\n",
        "# print(lr_gridCV.best_params_)\n",
        "# y_pred = lr_gridCV.predict(vectorised_test_documents)\n",
        "# print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3sw-ehpb0XtA",
        "colab_type": "code",
        "outputId": "edefe2d6-cfbe-4453-e139-d12b676a4f0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# logistic = LogisticRegression()\n",
        "# logistic = LogisticRegression(class_weight='balanced')\n",
        "logistic = LogisticRegression(class_weight={\"bs\":5,\"non-bs\":3})\n",
        "C = [0.1, 1]\n",
        "penalty = ['l1','l2']\n",
        "\n",
        "param_grid = dict(C=C, penalty=penalty)\n",
        "gs = GridSearchCV(logistic, param_grid=param_grid, cv= 5, scoring='accuracy')\n",
        "\n",
        "gs.fit(X_train, y_train)\n",
        "print(gs.best_params_)\n",
        "\n",
        "y_pred=gs.predict(X_test)\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"F1:\",metrics.f1_score(y_test, y_pred, pos_label='bs'))\n",
        "print(metrics.confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'C': 1, 'penalty': 'l1'}\n",
            "Accuracy: 0.9706878306878307\n",
            "F1: 0.9290289520881373\n",
            "[[ 3626   218]\n",
            " [  336 14720]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mDBzVhtfPE-s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So by trying different algorisms and model tuning, eventually we found weighted LogisticRegression gives pretty good result. And we also learnt data enrichment and data transformation based on proper Interpretation are super crucial for machine learning."
      ]
    },
    {
      "metadata": {
        "id": "UHk1BwYHOYiq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "61a7dc42-ef39-4156-8c75-38544673d4f1"
      },
      "cell_type": "code",
      "source": [
        "print( all_data['text'].__class__)\n",
        "print( all_data['text'].head())"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "0    Print They should pay all the back all the mon...\n",
            "1    Why Did Attorney General Loretta Lynch Plead T...\n",
            "2    Red State : \\nFox News Sunday reported this mo...\n",
            "3    Email Kayla Mueller was a prisoner and torture...\n",
            "4    Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...\n",
            "Name: text, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G0lgPrthRL5U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sentiment(x):\n",
        "    score = sid.polarity_scores(x)\n",
        "    return score['compound']\n",
        "\n",
        "data = np.array([\"Had President Donald Trump been successful in launching prosecutions against Hillary Clinton and James Comey, it could have spelled the end of his presidency, as a clear-cut abuse of power.\\\n",
        "It never happened, apparently thwarted by then-White House Counsel Don McGahn and other senior officials. But that does not mean this is a crisis dodged for Trump and he is now free from fresh legal and political jeopardy. Quite the reverse.\\\n",
        "RELATED: Trump raised prosecuting Clinton with top White House, Justice officials\\\n",
        "At the very least, the latest developments underline how Trump's senior subordinates may have shielded a President unschooled in constitutional norms from disastrous steps that could have put his presidency in peril.\\\n",
        "And it leaves anyone on the outside wondering what other potential disasters top officials like McGahn, former Attorney General Jeff Sessions and current Deputy Attorney General Rod Rosenstein might have prevented.\\\n",
        "They also raise questions about the capacity of a now-understaffed White House and legal counsel's operation to protect the President from current or future transgressions.\\\n",
        "It will be impossible to confirm, given the habitual silence from the special counsel's office, but the revelations hint at the possibility that Robert Mueller knows much more about what went on in the corridors of the West Wing than has been publicly revealed.\\\n",
        "That will play into rising tensions in Washington amid expectations that the endgame of Mueller's probe is in sight and speculation about possible indictments targeting Trump world and the content of his final report.\\\n",
        "Bombshell reports by CNN and The New York Times about the President's intentions emerged on another surreal day in Washington that saw shocking disclosures about Ivanka Trump's emails and a huge foreign policy pivot over Saudi Arabia.\"])\n",
        "s = pd.Series(data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uOqlR8dLS838",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Play with LDA\n"
      ]
    },
    {
      "metadata": {
        "id": "FZYe8WKyZsfT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokens = data_kg_fake_news['text'].astype('U').apply(tokenize2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OTsXQmvdZ0So",
        "colab_type": "code",
        "outputId": "faaab7f1-bdc7-48d4-f98f-b17be88dbc30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "print(tokens.__class__)\n",
        "print(tokens.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "(12999,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TtdM-Lq2gaEx",
        "colab_type": "code",
        "outputId": "36a01375-04ac-446d-9613-644fc1ea709f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U gensim\n",
        "\n",
        "from gensim import corpora, models\n",
        "import gensim\n",
        "\n",
        "dictionary = corpora.Dictionary(tokens)\n",
        "print(dictionary.__class__)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.7.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied, skipping upgrade: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.62)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.11.29)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.3)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.1.13)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.13.0,>=1.12.62 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.62)\n",
            "Requirement already satisfied, skipping upgrade: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.62->boto3->smart-open>=1.2.1->gensim) (0.14)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.62->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "<class 'gensim.corpora.dictionary.Dictionary'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6fKoEcXBhNmd",
        "colab_type": "code",
        "outputId": "fef31912-5abd-4efa-fedd-4c5e2b342cb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(dictionary.token2id))\n",
        "corpus = [dictionary.doc2bow(text) for text in tokens]\n",
        "print(len(corpus))\n",
        "print(data_kg_fake_news['text'][123])\n",
        "print(tokens[123])\n",
        "print(len(corpus[123]))\n",
        "print(corpus[123])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "122005\n",
            "12999\n",
            "Same people all the time , i dont know how you can fix this corruption http://www.fromthewilderness.com/free/ww3/10_09_01_krongard.html\n",
            "['peopl', 'time', 'dont', 'know', 'fix', 'corrupt', 'http']\n",
            "7\n",
            "[(68, 1), (329, 1), (563, 1), (651, 1), (709, 1), (4324, 1), (4846, 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4tFGyhSujQpo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=3, id2word = dictionary, passes=10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KDzLCRW6kWpY",
        "colab_type": "code",
        "outputId": "45786d48-cb9f-404f-ac66-a760c1733405",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "print(ldamodel.print_topics(num_topics=-1, num_words=9))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, '0.005*\"peopl\" + 0.005*\"one\" + 0.004*\"war\" + 0.004*\"world\" + 0.004*\"state\" + 0.004*\"would\" + 0.004*\"time\" + 0.004*\"year\" + 0.003*\"govern\"'), (1, '0.014*\"que\" + 0.008*\"del\" + 0.005*\"die\" + 0.005*\"por\" + 0.004*\"der\" + 0.004*\"con\" + 0.004*\"para\" + 0.004*\"vaccin\" + 0.004*\"cancer\"'), (2, '0.014*\"clinton\" + 0.013*\"trump\" + 0.009*\"hillari\" + 0.008*\"elect\" + 0.005*\"state\" + 0.005*\"vote\" + 0.005*\"email\" + 0.005*\"obama\" + 0.005*\"said\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8SJaCuuqm-Lh",
        "colab_type": "code",
        "outputId": "043ea15c-8bdd-4df7-856c-7dd1dbbdc0bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(ldamodel[(68, 1), (329, 1), (563, 1), (651, 1), (709, 1), (4324, 1), (4846, 1)])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 0.04787037), (1, 0.0457006), (2, 0.90642905)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DozidSlJnfDX",
        "colab_type": "code",
        "outputId": "b79fc313-e6fd-43d4-ea8b-a27bbc523219",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "tokens_test = s.astype('U').apply(tokenize2)\n",
        "corpus_test = [dictionary.doc2bow(text) for text in tokens_test]\n",
        "print(ldamodel[corpus_test[0]])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 0.2268284), (2, 0.7710221)]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}